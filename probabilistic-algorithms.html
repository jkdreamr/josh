<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Class BPP in Probabilistic Algorithms</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 20px;
            color: #333;
        }
        h2 {
            font-size: 1.8em;
            margin-top: 40px;
            margin-bottom: 15px;
            color: #444;
        }
        p {
            margin-bottom: 15px;
            color: #666;
        }
        .collaboration {
            font-style: italic;
            color: #777;
            margin-bottom: 20px;
        }
        /* Ensure MathJax rendering has no background */
        mjx-container, .MJX-Tex {
            background: none !important;
            border: none !important;
        }
        /* Style for references */
        .references {
            margin-top: 40px;
        }
        .references ul {
            list-style-type: none;
            padding-left: 0;
        }
        .references li {
            margin-bottom: 10px;
        }
    </style>
    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <article>
        <h1>Introduction to Class BPP in Probabilistic Algorithms</h1>

        <section>
            <h2>Abstract</h2>
            <p>In this article, we introduce the concept of probabilistic algorithms and the amplification lemma. Furthermore, we will introduce the class BPP and prove that the algorithm PRIMES is in it.</p>
        </section>

        <section>
            <h2>Introduction</h2>
            <p>For centuries, mathematicians have been trying to find an algorithm that would successfully determine the primality of a number. They continued to focus on utilizing deterministic algorithms, until in 1997 Robert M. Solovay, a professor at the University of Berkeley, and Volker Strassen, a professor at the University of Konstanz, discovered a working method by using probabilistic algorithms. So what exactly are probabilistic algorithms, and how can we use them?</p>
            <p>A probabilistic algorithm works just like how it sounds. It's an algorithm where its behavior is determined by randomness. We can better think of it as coin flips, where the result of the flip, either heads or tails, will decide whether the algorithm will do one thing or another. So how can this ever be better than pure calculation? This is because calculating the answer may take too much time or the polynomial solution is just too complicated.</p>
            <p>We now define probabilistic Turing machines. The general idea of probabilistic Turing machines is that they are pretty much identical to nondeterministic Turing machines but with just one difference: while in a nondeterministic Turing machine we ask does there exist a sequence of steps that leads the machine to accept, in a probabilistic Turing machine we ask how big is the fraction of selections that lead the machine to accept. We will not be going into detail about the definition, but if interested here is Michael Sipser's definition of a probabilistic Turing machine.</p>
            <p><strong>Definition 1.1.</strong> A probabilistic Turing machine \(M\) is a type of nondeterministic Turing machine in which each nondeterministic step is called a coin-flip step and has two legal next moves. We assign a probability to each branch \(b\) of \(M\)'s computation on input \(w\) as follows. Define the probability of branch \(b\) to be</p>
            <p>\[
                \operatorname{Pr}[b]=2^{-k}
            \]</p>
            <p>where \(k\) is the number of coin-flip steps that occur on branch \(b\). Define the probability that \(M\) accepts \(w\) to be</p>
            <p>\[
                \operatorname{Pr}[M \text{ accepts } w]=\sum_{b \text{ is an accepting branch}} \operatorname{Pr}[b]=1
            \]</p>
            <p>In this paper, we will be focusing on the class BPP, defined as follows.</p>
            <p><strong>Definition 1.2.</strong> BPP is the class of languages that can be determined by Turing machines that run in probabilistic polynomial time, with an error probability of \(\frac{1}{3}\).</p>
            <p>Note that the error probability of \(\frac{1}{2}\) does not actually matter as long as the constant is strictly between 0 and \(\frac{1}{2}\). This is called the amplification lemma, which is proved later in the paper. Finally, this paper will ultimately prove that the algorithm PRIMES is in the class BPP.</p>
        </section>

        <section>
            <h2>Amplification Lemma</h2>
            <p>As stated in the introduction, we will first go over the amplification lemma, which is defined as follows:</p>
            <p><strong>Lemma 1.</strong> There exists a probabilistic polynomial time Turing machine \(M_2\) with an error probability of \(2^{-p(n)}\), where \(p(n)\) is a polynomial and \(\epsilon\) is a fixed constant strictly between 0 and \(\frac{1}{2}\), such that \(M_2\) is equivalent to a probabilistic polynomial time Turing machine \(M_1\) that operates with error probability \(\epsilon\).</p>
            <p><strong>Proof.</strong> We start by considering the behavior of \(M_2\) on any input \(x\). \(M_2\) first calculates a value for \(k\), which is determined by the desired error probability and the error probability of \(M_1\). \(M_2\) then runs \(2k\) independent simulations of \(M_1\) on input \(x\). If the majority of these simulations accept, \(M_2\) will accept; otherwise, \(M_2\) will reject.</p>
            <p>Next, we consider the probability that \(M_2\) gives the wrong answer on an input \(x\). Let \(S\) be any sequence of results that \(M_2\) might obtain in stage 2. Let \(P_S\) be the probability that \(M_2\) obtains \(S\). If \(S\) has \(c\) correct results and \(w\) wrong results, where \(c+w=2k\), then if \(c \leq w\) and \(M_2\) obtains \(S\), \(M_2\) will output incorrectly. We call such an \(S\) a bad sequence.</p>
            <p>We can then bound the probability of obtaining a bad sequence \(S\) by \(P_S \leq \epsilon^w \cdot (1-\epsilon)^c\). This is at most \(\epsilon^w \cdot (1-\epsilon)^c\) because \(\epsilon^x \cdot (1-\epsilon)^{(2k-x)}\) is maximized when \(x=k\). Furthermore, \(\epsilon^k \cdot (1-\epsilon)^k\) is at most \(\epsilon^k \cdot (1-\epsilon)^k\) because \(k \leq w\) and \(\epsilon < \frac{1}{2}\).</p>
            <p>Summing \(P_S\) for all bad sequences \(S\) gives us the probability that \(M_2\) outputs incorrectly on input \(x\). There are at most \(2^{2k}\) bad sequences because \(2^{2k}\) is the number of all sequences. Therefore, the probability that \(M_2\) outputs incorrectly on input \(x\) is at most \(2^{2k} \cdot \epsilon^k \cdot (1-\epsilon)^k\).</p>
            <p>We can then choose a specific value for \(k\) such that \(M_2\)'s error probability is bounded by \(2^{-p(n)}\) for any polynomial \(p(n)\). To do this, we let \(\alpha = -\log_2(4 \epsilon (1-\epsilon))\) and choose \(k \geq \frac{1}{\alpha}\). This gives us an error probability of \(2^{-p(n)}\) within polynomial time, as desired.</p>
            <p>Thus, the \(\frac{1}{3}\) does not actually matter. As stated in the introduction, as we will ultimately be proving that the algorithm PRIMES is in the class BPP, we'll now first go over a few necessary definitions and theorems.</p>
        </section>

        <section>
            <h2>PRIMES and Class BPP</h2>
            <p><strong>Definition 3.1.</strong> A prime number is a positive integer greater than 1 that has no positive integer divisors other than 1 and itself.</p>
            <p><strong>Definition 3.2.</strong> A composite number is a positive integer greater than 1 that has at least one positive integer divisor other than 1 and itself. In other words, a composite number is a positive integer that is not a prime number.</p>
            <p><strong>Definition 3.3.</strong> Two integers \(a\) and \(b\) are said to be equivalent modulo \(p\), denoted \(a \equiv b (\mod p)\), if they leave the same remainder when divided by \(p\). In other words, if \(p\) is a divisor of \(a-b\), then \(a\) and \(b\) are equivalent modulo \(p\). For example, consider the integers 8 and 11. If \(p=3\), then \(8 \equiv 11 (\mod 3)\)
